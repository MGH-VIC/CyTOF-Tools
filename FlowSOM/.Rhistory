View(tmp_dat)
#Aggregate "scaled_dat" columns x:y, by scaled_dat$Cluster, function is median
heatmap_input = aggregate(scaled_dat[, 1:2], list(scaled_dat$Cluster), median)
View(heatmap_input)
View(heatmap_input)
#Extract Median Marker Intensity for Each cluster
Marker_intensity = as.data.frame(fsom$map$medianValues)
rownames(Marker_intensity) = paste("Cluster", seq(1:nrow(Marker_intensity)))
View(Marker_intensity)
rownames(heatmap_input)=paste("Cluster",heatmap_input$Group.1,sep = " ")
View(heatmap_input)
rownames(heatmap_input)=paste("Cluster",heatmap_input$Group.1,sep = " ");heatmap_input = heatmap_input[,-c("Group.1")]
library(tibble)
#Aggregate "scaled_dat" columns x:y, by scaled_dat$Cluster, function is median
heatmap_input = aggregate(scaled_dat[, 1:2], list(scaled_dat$Cluster), median)
View(heatmap_input)
heatmap_input = column_to_rownames(heatmap_input, var = "Group.1")
View(heatmap_input)
rownames(heatmap_input)=paste("Cluster",rownames(heatmap_input),sep = " ")
View(heatmap_input)
#Now plot the heatmap z scored for the metaclusters
z_inp = aggregate(scaled_dat[, 1:2], list(scaled_dat$MetaCluster), median)
z_inp = column_to_rownames(z_inp, var = "Group.1")
rownames(z_inp)=paste("Cluster",rownames(z_inp),sep = " ")
View(z_inp)
library(xlsx)
install.packages("xlsx")
library(xlsx)
#Export Results for all data
# Create a blank workbook
OUT <- createWorkbook()
#Export Results for all data
# Create a blank workbook
OUT <- createWorkbook()
# Add sheets to the workbook
addWorksheet(OUT, "Raw Cell Data")
addWorksheet(OUT, "Scaled Cell Data")
addWorksheet(OUT, "Median Raw Cell Data - Clusters")
addWorksheet(OUT, "Median Raw Cell Data -  Metaclusters")
addWorksheet(OUT, "Median scaled Cell Data - Clusters")
addWorksheet(OUT, "Median scaled Cell Data - Metaclusters")
#Export Results for all data
# Create a blank workbook
OUT <- createWorkbook()
# Add sheets to the workbook
addWorksheet(OUT, "Cell Data")
addWorksheet(OUT, "Scaled Cell Data")
addWorksheet(OUT, "Median Cell Data - Clusters")
addWorksheet(OUT, "Median Cell Data -  Metaclusters")
addWorksheet(OUT, "Median scaled Data - Clusters")
addWorksheet(OUT, "Median scaled Data - Metaclusters")
#Export Results for all data
# Create a blank workbook
OUT <- createWorkbook()
# Add sheets to the workbook
addWorksheet(OUT, "Cell Data")
addWorksheet(OUT, "Scaled Cell Data")
addWorksheet(OUT, "Median Cell Data_Clusters")
addWorksheet(OUT, "Median Cell Data_Metaclusters")
addWorksheet(OUT, "Median scaled Data_Clusters")
addWorksheet(OUT, "Median scaled Data_Metaclusters")
#Extract Median Marker Intensity for Each cluster
Med_intensity = as.data.frame(fsom$map$medianValues)
rownames(Marker_intensity) = paste("Cluster", seq(1:nrow(Med_intensity)))
#Plot heatmap of median marker intensity per metacluster
heatmap_input = aggregate(scaled_dat[, 1:2], list(Cell_data$MetaCluster), median)
#Plot heatmap of median marker intensity per metacluster
med_meta = aggregate(scaled_dat[, 1:2], list(Cell_data$MetaCluster), median)
View(med_meta)
library(openCyto)
library(FlowSOM)
library(flowCore)
library(dplyr)
library(ggplot2)
library(stringr)
library(pheatmap)
library(tibble)
library(doParallel)
library(openxlsx)
library(utils)
library(rowr)
library(stats)
library(multcompView)
library(tools)
library(tibble)
source("clustering_data_import.R")
#Set your working directory to read the data
setwd("/Users/reevesteammm2/Desktop/FlowSOM")
#Input name for analysis result (Can help to add dates on the end)
analysis_name = "FlowSOM"
#Get names of the csv files in your directory (Change this to "*.fcs" for fcs files)
files_list = list.files(pattern="*.fcs")
#Read the full files in your dataset (all files in your files_list)
temp_data = lapply(files_list,data.read.full)
full_data = do.call(rbind,temp_data)
#Get normalization parameters (percentiles for each parameter that you input for the full dataset)
norm_parameter = get.normalize(full_data,percentile = 0.995, cols_to_use = c(5:6))
#subsample the full data
subsampled_data = data.subsample(full_data,perc_of_total = 0.1)
#Run the data normalization function for the samples
#!Must have cols_to_use the same as for get.normalize function!
#Will normalize your data to the percentile that you chose for get.normalize function
normed_input = data.normalize(mydata = subsampled_data,norm_input = norm_parameter, cols_to_use = c(5:6))
#Filter your data to the percentile that you choose (Will throw out the top percentile)
#Think about whether you want to do this for the full, combined datasets, or for each individual dataset
filtered_input = data.filtering(data_to_filter = normed_input,percentile = 0.995,cols_to_use = c(1:2))
#Convert data to flow frame so we can input to flowSOM
data_fsom = flowCore::flowFrame(as.matrix(filtered_input))
#Transform data and Run flowSOM
#Here you will want to choose xdim and ydim as the same. The function only takes in square grids. You choose final number of clusters in the
#metaclustering step
asinh_cofactor = 5
input_data <- FlowSOM::ReadInput(data_fsom, transform = TRUE, scale = FALSE,
toTransform = c(1:2),
transformFunction = function(data_fsom){
data_fsom = asinh(data_fsom/asinh_cofactor)
})
set.seed(123121)
fsom <- FlowSOM::BuildSOM(input_data, colsToUse = c(1:2),
xdim=4,ydim=4)
#Build Minimum spanning tree
MST_fsom = FlowSOM::BuildMST(fsom = fsom)
#Perform metaclustering for final clusters
#Options are metaClustering_consensus,metaClustering_hclust, metaClustering_kmeans,metaClustering_som
#nClus gives you the final clustering
metaclus = FlowSOM::MetaClustering(MST_fsom$map$codes,
"metaClustering_kmeans",nClus = 10)
#Append Cell data to include a column for Cluster Assignments
meta_assign <- metaclus[MST_fsom$map$mapping[,1]]
Cell_data = as.data.frame(cbind(fsom$data, fsom$map$mapping[,1],as.data.frame(meta_assign)))
colnames(Cell_data)[(ncol(Cell_data)-1):ncol(Cell_data)] = c("Cluster","MetaCluster")
#Extract Median Marker Intensity for Each cluster
Med_intensity = as.data.frame(fsom$map$medianValues)
rownames(Marker_intensity) = paste("Cluster", seq(1:nrow(Med_intensity)))
#Plot heatmap of median marker intensity per cluster
jpeg(paste("Median Intensity Heatmap_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
pheatmap(Med_intensity[,1:2],
cluster_cols = FALSE,
cluster_rows = TRUE,
clustering_distance_rows = "euclidean",
clustering_method = "ward.D2",
cellwidth = 20,
cellheight = 20)
dev.off()
#Plot heatmap of median marker intensity per metacluster
med_meta = aggregate(scaled_dat[, 1:2], list(Cell_data$MetaCluster), median)
med_meta = column_to_rownames(med_meta, var = "Group.1")
rownames(med_meta)=paste("Meta Cluster",rownames(med_meta),sep = " ")
jpeg(paste("Median Meta Intensity Heatmap_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
pheatmap(med_meta[,1:2],
cluster_cols = FALSE,
cluster_rows = TRUE,
clustering_distance_rows = "euclidean",
clustering_method = "ward.D2",
cellwidth = 20,
cellheight = 20)
dev.off()
#Scale each channel for each cell as z-score
scaled_dat = Cell_data
scaled_dat[c(1,2)] <- lapply(Cell_data[c(1, 2)], function(x) c(scale(x)))
#Aggregate "scaled_dat" columns x:y, by scaled_dat$Cluster, function is median
heatmap_input_z = aggregate(scaled_dat[, 1:2], list(scaled_dat$Cluster), median)
heatmap_input_z = column_to_rownames(heatmap_input_z, var = "Group.1")
rownames(heatmap_input_z)=paste("Cluster",rownames(heatmap_input_z),sep = " ")
#Plot the median of the z-scored data
jpeg(paste("z_score Median Intensity Heatmap_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
pheatmap(heatmap_input_z,
cluster_cols = FALSE,
cluster_rows = TRUE,
clustering_distance_rows = "euclidean",
clustering_method = "ward.D2",
cellwidth = 20,
cellheight = 20)
dev.off()
#Now plot the heatmap z scored for the metaclusters
z_inp = aggregate(scaled_dat[, 1:2], list(scaled_dat$MetaCluster), median)
z_inp = column_to_rownames(z_inp, var = "Group.1")
rownames(z_inp)=paste("Meta Cluster",rownames(z_inp),sep = " ")
#Plot the median of the z-scored data
jpeg(paste("z_score Median Meta Intensity Heatmap_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
pheatmap(z_inp,
cluster_cols = FALSE,
cluster_rows = TRUE,
clustering_distance_rows = "euclidean",
clustering_method = "ward.D2",
cellwidth = 20,
cellheight = 20)
dev.off()
#Export Results for all data
# Create a blank workbook
OUT <- createWorkbook()
# Add sheets to the workbook
addWorksheet(OUT, "Cell Data")
addWorksheet(OUT, "Scaled Cell Data")
addWorksheet(OUT, "Median Cell Data_Clusters")
addWorksheet(OUT, "Median Cell Data_Metaclusters")
addWorksheet(OUT, "Median scaled Data_Clusters")
addWorksheet(OUT, "Median scaled Data_Metaclusters")
# Write the data to the sheets
writeData(OUT, sheet = "Cell Data", x = Cell_data)
writeData(OUT, sheet = "Scaled Cell Data", x = scaled_dat)
writeData(OUT, sheet = "Median Cell Data_Clusters", x = Med_intensity)
writeData(OUT, sheet = "Median Cell Data_Metaclusters", x = med_meta)
writeData(OUT, sheet = "Median scaled Data_Clusters", x = heatmap_input_z)
writeData(OUT, sheet = "Median scaled Data_Metaclusters", x = z_inp)
# Export the file
saveWorkbook(OUT, "My output file.xlsx")
#flowSOM analysis
#Joshua Hess
library(openCyto)
library(FlowSOM)
library(flowCore)
library(dplyr)
library(ggplot2)
library(stringr)
library(pheatmap)
library(tibble)
library(doParallel)
library(openxlsx)
library(utils)
library(rowr)
library(stats)
library(multcompView)
library(tools)
library(tibble)
source("clustering_data_import.R")
#Set your working directory to read the data
setwd("/Users/reevesteammm2/Desktop/FlowSOM")
#Input name for analysis result (Can help to add dates on the end)
analysis_name = "FlowSOM"
#Get names of the csv files in your directory (Change this to "*.fcs" for fcs files)
files_list = list.files(pattern="*.fcs")
#Read the full files in your dataset (all files in your files_list)
temp_data = lapply(files_list,data.read.full)
full_data = do.call(rbind,temp_data)
#Get normalization parameters (percentiles for each parameter that you input for the full dataset)
norm_parameter = get.normalize(full_data,percentile = 0.995, cols_to_use = c(5:6))
#subsample the full data
subsampled_data = data.subsample(full_data,perc_of_total = 0.1)
#Run the data normalization function for the samples
#!Must have cols_to_use the same as for get.normalize function!
#Will normalize your data to the percentile that you chose for get.normalize function
normed_input = data.normalize(mydata = subsampled_data,norm_input = norm_parameter, cols_to_use = c(5:6))
#Filter your data to the percentile that you choose (Will throw out the top percentile)
#Think about whether you want to do this for the full, combined datasets, or for each individual dataset
filtered_input = data.filtering(data_to_filter = normed_input,percentile = 0.995,cols_to_use = c(1:2))
#Convert data to flow frame so we can input to flowSOM
data_fsom = flowCore::flowFrame(as.matrix(filtered_input))
#Transform data and Run flowSOM
#Here you will want to choose xdim and ydim as the same. The function only takes in square grids. You choose final number of clusters in the
#metaclustering step
asinh_cofactor = 5
input_data <- FlowSOM::ReadInput(data_fsom, transform = TRUE, scale = FALSE,
toTransform = c(1:2),
transformFunction = function(data_fsom){
data_fsom = asinh(data_fsom/asinh_cofactor)
})
set.seed(123121)
fsom <- FlowSOM::BuildSOM(input_data, colsToUse = c(1:2),
xdim=4,ydim=4)
#Build Minimum spanning tree
MST_fsom = FlowSOM::BuildMST(fsom = fsom)
#Perform metaclustering for final clusters
#Options are metaClustering_consensus,metaClustering_hclust, metaClustering_kmeans,metaClustering_som
#nClus gives you the final clustering
metaclus = FlowSOM::MetaClustering(MST_fsom$map$codes,
"metaClustering_kmeans",nClus = 10)
#Append Cell data to include a column for Cluster Assignments
meta_assign <- metaclus[MST_fsom$map$mapping[,1]]
Cell_data = as.data.frame(cbind(fsom$data, fsom$map$mapping[,1],as.data.frame(meta_assign)))
colnames(Cell_data)[(ncol(Cell_data)-1):ncol(Cell_data)] = c("Cluster","MetaCluster")
#Extract Median Marker Intensity for Each cluster
Med_intensity = as.data.frame(fsom$map$medianValues)
rownames(Marker_intensity) = paste("Cluster", seq(1:nrow(Med_intensity)))
#Plot heatmap of median marker intensity per cluster
jpeg(paste("Median Intensity Heatmap_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
pheatmap(Med_intensity[,1:2],
cluster_cols = FALSE,
cluster_rows = TRUE,
clustering_distance_rows = "euclidean",
clustering_method = "ward.D2",
cellwidth = 20,
cellheight = 20)
dev.off()
#Plot heatmap of median marker intensity per metacluster
med_meta = aggregate(Cell_data[, 1:2], list(Cell_data$MetaCluster), median)
med_meta = column_to_rownames(med_meta, var = "Group.1")
rownames(med_meta)=paste("Meta Cluster",rownames(med_meta),sep = " ")
jpeg(paste("Median Meta Intensity Heatmap_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
pheatmap(med_meta[,1:2],
cluster_cols = FALSE,
cluster_rows = TRUE,
clustering_distance_rows = "euclidean",
clustering_method = "ward.D2",
cellwidth = 20,
cellheight = 20)
dev.off()
#Scale each channel for each cell as z-score
scaled_dat = Cell_data
scaled_dat[c(1,2)] <- lapply(Cell_data[c(1, 2)], function(x) c(scale(x)))
#Aggregate "scaled_dat" columns x:y, by scaled_dat$Cluster, function is median
heatmap_input_z = aggregate(scaled_dat[, 1:2], list(scaled_dat$Cluster), median)
heatmap_input_z = column_to_rownames(heatmap_input_z, var = "Group.1")
rownames(heatmap_input_z)=paste("Cluster",rownames(heatmap_input_z),sep = " ")
#Plot the median of the z-scored data
jpeg(paste("z_score Median Intensity Heatmap_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
pheatmap(heatmap_input_z,
cluster_cols = FALSE,
cluster_rows = TRUE,
clustering_distance_rows = "euclidean",
clustering_method = "ward.D2",
cellwidth = 20,
cellheight = 20)
dev.off()
#Now plot the heatmap z scored for the metaclusters
z_inp = aggregate(scaled_dat[, 1:2], list(scaled_dat$MetaCluster), median)
z_inp = column_to_rownames(z_inp, var = "Group.1")
rownames(z_inp)=paste("Meta Cluster",rownames(z_inp),sep = " ")
#Plot the median of the z-scored data
jpeg(paste("z_score Median Meta Intensity Heatmap_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
pheatmap(z_inp,
cluster_cols = FALSE,
cluster_rows = TRUE,
clustering_distance_rows = "euclidean",
clustering_method = "ward.D2",
cellwidth = 20,
cellheight = 20)
dev.off()
#Export Results for all data
# Create a blank workbook
OUT <- createWorkbook()
# Add sheets to the workbook
addWorksheet(OUT, "Cell Data")
addWorksheet(OUT, "Scaled Cell Data")
addWorksheet(OUT, "Median Cell Data_Clusters")
addWorksheet(OUT, "Median Cell Data_Metaclusters")
addWorksheet(OUT, "Median scaled Data_Clusters")
addWorksheet(OUT, "Median scaled Data_Metaclusters")
# Write the data to the sheets
writeData(OUT, sheet = "Cell Data", x = Cell_data)
writeData(OUT, sheet = "Scaled Cell Data", x = scaled_dat)
writeData(OUT, sheet = "Median Cell Data_Clusters", x = Med_intensity)
writeData(OUT, sheet = "Median Cell Data_Metaclusters", x = med_meta)
writeData(OUT, sheet = "Median scaled Data_Clusters", x = heatmap_input_z)
writeData(OUT, sheet = "Median scaled Data_Metaclusters", x = z_inp)
# Export the file
saveWorkbook(OUT, "My output file.xlsx")
library(openCyto)
library(FlowSOM)
library(flowCore)
library(dplyr)
library(ggplot2)
library(stringr)
library(pheatmap)
library(tibble)
library(doParallel)
library(openxlsx)
library(utils)
library(rowr)
library(stats)
library(multcompView)
library(tools)
library(tibble)
source("clustering_data_import.R")
#Set your working directory to read the data
setwd("/Users/reevesteammm2/Desktop/FlowSOM")
#Input name for analysis result (Can help to add dates on the end)
analysis_name = "FlowSOM"
#Get names of the csv files in your directory (Change this to "*.fcs" for fcs files)
files_list = list.files(pattern="*.fcs")
#Read the full files in your dataset (all files in your files_list)
temp_data = lapply(files_list,data.read.full)
full_data = do.call(rbind,temp_data)
#Get normalization parameters (percentiles for each parameter that you input for the full dataset)
norm_parameter = get.normalize(full_data,percentile = 0.995, cols_to_use = c(5:6))
#subsample the full data
subsampled_data = data.subsample(full_data,perc_of_total = 0.1)
#Run the data normalization function for the samples
#!Must have cols_to_use the same as for get.normalize function!
#Will normalize your data to the percentile that you chose for get.normalize function
normed_input = data.normalize(mydata = subsampled_data,norm_input = norm_parameter, cols_to_use = c(5:6))
#Filter your data to the percentile that you choose (Will throw out the top percentile)
#Think about whether you want to do this for the full, combined datasets, or for each individual dataset
filtered_input = data.filtering(data_to_filter = normed_input,percentile = 0.995,cols_to_use = c(1:2))
#Convert data to flow frame so we can input to flowSOM
data_fsom = flowCore::flowFrame(as.matrix(filtered_input))
#Transform data and Run flowSOM
#Here you will want to choose xdim and ydim as the same. The function only takes in square grids. You choose final number of clusters in the
#metaclustering step
asinh_cofactor = 5
input_data <- FlowSOM::ReadInput(data_fsom, transform = TRUE, scale = FALSE,
toTransform = c(1:2),
transformFunction = function(data_fsom){
data_fsom = asinh(data_fsom/asinh_cofactor)
})
set.seed(123121)
fsom <- FlowSOM::BuildSOM(input_data, colsToUse = c(1:2),
xdim=4,ydim=4)
#Build Minimum spanning tree
MST_fsom = FlowSOM::BuildMST(fsom = fsom)
#Perform metaclustering for final clusters
#Options are metaClustering_consensus,metaClustering_hclust, metaClustering_kmeans,metaClustering_som
#nClus gives you the final clustering
metaclus = FlowSOM::MetaClustering(MST_fsom$map$codes,
"metaClustering_kmeans",nClus = 10)
#Append Cell data to include a column for Cluster Assignments
meta_assign <- metaclus[MST_fsom$map$mapping[,1]]
Cell_data = as.data.frame(cbind(fsom$data, fsom$map$mapping[,1],as.data.frame(meta_assign)))
colnames(Cell_data)[(ncol(Cell_data)-1):ncol(Cell_data)] = c("Cluster","MetaCluster")
#Extract Median Marker Intensity for Each cluster
Med_intensity = as.data.frame(fsom$map$medianValues)
rownames(Med_intensity) = paste("Cluster", seq(1:nrow(Med_intensity)))
#Plot heatmap of median marker intensity per cluster
jpeg(paste("Median Intensity Heatmap_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
pheatmap(Med_intensity[,1:2],
cluster_cols = FALSE,
cluster_rows = TRUE,
clustering_distance_rows = "euclidean",
clustering_method = "ward.D2",
cellwidth = 20,
cellheight = 20)
dev.off()
#Plot heatmap of median marker intensity per metacluster
med_meta = aggregate(Cell_data[, 1:2], list(Cell_data$MetaCluster), median)
med_meta = column_to_rownames(med_meta, var = "Group.1")
rownames(med_meta)=paste("Meta Cluster",rownames(med_meta),sep = " ")
jpeg(paste("Median Meta Intensity Heatmap_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
pheatmap(med_meta[,1:2],
cluster_cols = FALSE,
cluster_rows = TRUE,
clustering_distance_rows = "euclidean",
clustering_method = "ward.D2",
cellwidth = 20,
cellheight = 20)
dev.off()
#Scale each channel for each cell as z-score
scaled_dat = Cell_data
scaled_dat[c(1,2)] <- lapply(Cell_data[c(1, 2)], function(x) c(scale(x)))
#Aggregate "scaled_dat" columns x:y, by scaled_dat$Cluster, function is median
heatmap_input_z = aggregate(scaled_dat[, 1:2], list(scaled_dat$Cluster), median)
heatmap_input_z = column_to_rownames(heatmap_input_z, var = "Group.1")
rownames(heatmap_input_z)=paste("Cluster",rownames(heatmap_input_z),sep = " ")
#Plot the median of the z-scored data
jpeg(paste("z_score Median Intensity Heatmap_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
pheatmap(heatmap_input_z,
cluster_cols = FALSE,
cluster_rows = TRUE,
clustering_distance_rows = "euclidean",
clustering_method = "ward.D2",
cellwidth = 20,
cellheight = 20)
dev.off()
#Now plot the heatmap z scored for the metaclusters
z_inp = aggregate(scaled_dat[, 1:2], list(scaled_dat$MetaCluster), median)
z_inp = column_to_rownames(z_inp, var = "Group.1")
rownames(z_inp)=paste("Meta Cluster",rownames(z_inp),sep = " ")
#Plot the median of the z-scored data
jpeg(paste("z_score Median Meta Intensity Heatmap_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
pheatmap(z_inp,
cluster_cols = FALSE,
cluster_rows = TRUE,
clustering_distance_rows = "euclidean",
clustering_method = "ward.D2",
cellwidth = 20,
cellheight = 20)
dev.off()
#Export Results for all data
# Create a blank workbook
OUT <- createWorkbook()
# Add sheets to the workbook
addWorksheet(OUT, "Cell Data")
addWorksheet(OUT, "Scaled Cell Data")
addWorksheet(OUT, "Median Cell Data_Clusters")
addWorksheet(OUT, "Median Cell Data_Metaclusters")
addWorksheet(OUT, "Median scaled Data_Clusters")
addWorksheet(OUT, "Median scaled Data_Metaclusters")
# Write the data to the sheets
writeData(OUT, sheet = "Cell Data", x = Cell_data)
writeData(OUT, sheet = "Scaled Cell Data", x = scaled_dat)
writeData(OUT, sheet = "Median Cell Data_Clusters", x = Med_intensity)
writeData(OUT, sheet = "Median Cell Data_Metaclusters", x = med_meta)
writeData(OUT, sheet = "Median scaled Data_Clusters", x = heatmap_input_z)
writeData(OUT, sheet = "Median scaled Data_Metaclusters", x = z_inp)
# Export the file
saveWorkbook(OUT, "My output file.xlsx")
#Plot the clustered data
# jpeg(paste("MST_16clusters_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
# PlotNumbers(MST_fsom)
# dev.off()
#Plot results
# jpeg(paste("MST_16clusters_color_",analysis_name,".jpeg", sep = ""), width = 2000, height = 2000, res = 180)
# PlotStars(MST_fsom)
# dev.off()
#Export Results for all data
# Create a blank workbook
OUT <- createWorkbook()
# Add sheets to the workbook
addWorksheet(OUT, "Cell Data")
addWorksheet(OUT, "Scaled Cell Data")
addWorksheet(OUT, "Median Cell Data_Clusters")
addWorksheet(OUT, "Median Cell Data_Metaclusters")
addWorksheet(OUT, "Median scaled Data_Clusters")
addWorksheet(OUT, "Median scaled Data_Metaclusters")
# Write the data to the sheets
writeData(OUT, sheet = "Cell Data", x = Cell_data,rowNames = TRUE)
writeData(OUT, sheet = "Scaled Cell Data", x = scaled_dat,rowNames = TRUE)
writeData(OUT, sheet = "Median Cell Data_Clusters", x = Med_intensity,rowNames = TRUE)
writeData(OUT, sheet = "Median Cell Data_Metaclusters", x = med_meta,rowNames = TRUE)
writeData(OUT, sheet = "Median scaled Data_Clusters", x = heatmap_input_z,rowNames = TRUE)
writeData(OUT, sheet = "Median scaled Data_Metaclusters", x = z_inp,rowNames = TRUE)
# Export the file
saveWorkbook(OUT, "My output file.xlsx")
