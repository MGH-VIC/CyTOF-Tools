#Functions for Running Regularized Logistic Regression
#Joshua Hess
require(caret)
require(doParallel)
require(MLmetrics)
require(varhandle)
require(openxlsx)
#Import custom function
source("ReadData.R")
input = ReadData(filename,sheetname,group_col,groups,cell_cols,not_cell_cols,scale_clusters=TRUE,cluster_prefix=NULL)
#Functions for Running Regularized Logistic Regression
#Joshua Hess
require(caret)
require(doParallel)
require(MLmetrics)
require(varhandle)
require(openxlsx)
#Import custom function
source("ReadData.R")
scale_clusters = TRUE
cluster_prefix = NULL
#Enter the name of your data sheet
filename="For Correlation Analysis 10302019.xlsx"
#Enter the name of the sheet of the data sheet you are using for calculations
sheetname = "Sheet1"
#Do you want to add a prefix to cluster names? If not, leave as NULL
cluster_prefix=NULL
#Which columns are you using as cells for calculation?
cell_cols = 20:31
#Which columns are you using as clinical measures? If none, use NULL and calculation will only be run for cells
not_cell_cols = 2:5
#Which column indicates the groups you are using?
group_col = 3
#Which groups are you wanting to use? (Ex. groups = c(1,2) if numbered Ex. groups = c("Vaccinated","Naive") if strings)
groups = c(1,2)
input = ReadData(filename,sheetname,group_col,groups,cell_cols,not_cell_cols,scale_clusters=TRUE,cluster_prefix=NULL)
if(class(input) == "list"){
print("Detected a list of data files")
#Get the cluster data and combine it with the group data
input = as.data.frame(cbind(input[["Clusters"]],input[["Group"]]))
#Fix the column names for the group column
colnames(input)[ncol(input)] = "Group"
}
input = ReadData(filename,sheetname,group_col,groups,cell_cols,not_cell_cols,scale_clusters=TRUE,cluster_prefix=NULL)
num_cores = 6
export_coeff=TRUE
cv_type = "repeated"
#Check to see if getting data from ReadData Function
if(class(input) == "list"){
print("Detected a list of data files")
#Get the cluster data and combine it with the group data
input = as.data.frame(cbind(input[["Clusters"]],input[["Group"]]))
#Fix the column names for the group column
colnames(input)[ncol(input)] = "Group"
}
#Run parallel for speed
registerDoParallel(cores = num_cores)
#Set up 'Group' column of data to be a factor
input$Group = as.factor(input$Group)
levels(input$Group) <- make.names(levels(factor(input$Group)))
#Set up cross validation parameters - bootstrap CV or repeated CV
if (cv_type == "bootstrap"){
custom <- caret::trainControl(method = "boot",
number = 1000,
p = 0.75,
verboseIter = TRUE,
summaryFunction = multiClassSummary,
savePredictions="final",returnData = TRUE,returnResamp = "all")
} else if (cv_type == "repeated"){
custom <- caret::trainControl(method = "repeatedcv",
number = 4,
repeats = 100,
verboseIter = TRUE,
summaryFunction = multiClassSummary,
savePredictions="final",returnData = TRUE,returnResamp = "all")
}
#Run logistic elastic net regression
set.seed(433)
set.seed(433)
ElasticNet <- caret::train(Group ~ . ,
input_to_reg,
method = 'glmnet',family = "binomial", standardize = FALSE,
tuneGrid = expand.grid(
lambda = seq(0, 1,length = 50),
alpha = seq(0,1,length = 50)),
trControl = custom)
#Run logistic elastic net regression
set.seed(433)
ElasticNet <- caret::train(Group ~ . ,
input,
method = 'glmnet',family = "binomial", standardize = FALSE,
tuneGrid = expand.grid(
lambda = seq(0, 1,length = 50),
alpha = seq(0,1,length = 50)),
trControl = custom)
export_cv = TRUE
export_cv_img = TRUE
#Plot cross validation
if (export_cv_img){
ggplot(data = ElasticNet) +
theme(text = element_text(size=17),
axis.text.x = element_text(face="bold", color="black", size=23, angle=0),
axis.text.y = element_text(face="bold", color="black", size=23, angle=0),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
panel.grid = element_line(colour = "grey"),
plot.margin = unit(c(2,2,2,2), "cm"),
axis.title.y = element_text(angle = 90, vjust = 10, hjust = 0.5, size = 25),
axis.title.x = element_text(angle = 0, vjust = -10, hjust = 0.5, size = 25),
legend.title = element_text(size=19),
legend.text = element_text(size=19))
ggsave(paste(day,levels(input$Group)[1],
levels(input$Group)[2],"Cross_valid.jpeg",sep = "_"),
plot = last_plot(), units = "mm",
width = 500, height = 300, limitsize = FALSE)
}
#Plot cross validation
if (export_cv_img){
ggplot(data = ElasticNet) +
theme(text = element_text(size=17),
axis.text.x = element_text(face="bold", color="black", size=23, angle=0),
axis.text.y = element_text(face="bold", color="black", size=23, angle=0),
panel.background = element_blank(),
axis.line = element_line(colour = "black"),
panel.grid = element_line(colour = "grey"),
plot.margin = unit(c(2,2,2,2), "cm"),
axis.title.y = element_text(angle = 90, vjust = 10, hjust = 0.5, size = 25),
axis.title.x = element_text(angle = 0, vjust = -10, hjust = 0.5, size = 25),
legend.title = element_text(size=19),
legend.text = element_text(size=19))
ggsave(paste(levels(input$Group)[1],
levels(input$Group)[2],"Cross_valid.jpeg",sep = "_"),
plot = last_plot(), units = "mm",
width = 500, height = 300, limitsize = FALSE)
}
#Export cross validation summary
if (export_cv){
cvSummary = as.data.frame(ElasticNet$results)
write.xlsx(cvSummary, paste(day,levels(input_to_reg$Group)[1],
levels(input_to_reg$Group)[2],
"Cross_valid_summary.xlsx",sep = "_"))
}
#Export cross validation summary
if (export_cv){
cvSummary = as.data.frame(ElasticNet$results)
write.xlsx(cvSummary, paste(levels(input_to_reg$Group)[1],
levels(input_to_reg$Group)[2],
"Cross_valid_summary.xlsx",sep = "_"))
}
#Export cross validation summary
if (export_cv){
cvSummary = as.data.frame(ElasticNet$results)
write.xlsx(cvSummary, paste(levels(input$Group)[1],
levels(input$Group)[2],
"Cross_valid_summary.xlsx",sep = "_"))
}
#Extract log odds coefficients
bestEN <- ElasticNet$finalModel
CoefficientsEN = as.matrix(coef(bestEN, s = ElasticNet$bestTune$lambda))
CoefficientsEN = as.data.frame(CoefficientsEN)
rownames(CoefficientsEN) = stringr::str_replace_all(rownames(CoefficientsEN),
"[`]", "")
colnames(CoefficientsEN)[1] = "Change in Log Odds per Unit Increase"
if (export_coeff){
write.xlsx(CoefficientsEN, paste(levels(input_to_reg$Group)[1],
levels(input_to_reg$Group)[2],
"Coeff.xlsx",sep = "_"),
row.names = TRUE)
}
if (export_coeff){
write.xlsx(CoefficientsEN, paste(levels(input$Group)[1],
levels(input$Group)[2],
"Coeff.xlsx",sep = "_"),
row.names = TRUE)
}
#Set up Coefficients waterfall plot data
CoefficientsEN = subset(CoefficientsEN, CoefficientsEN$`Change in Log Odds per Unit Increase`!=0)
CoefficientsEN = CoefficientsEN[2:nrow(CoefficientsEN),,drop = FALSE]
CoefficientsEN = CoefficientsEN[order(-CoefficientsEN$`Change in Log Odds per Unit Increase`),
, drop = FALSE]
CoefficientsEN$`Group` <- rownames(CoefficientsEN)  # create new column for car names
CoefficientsEN$Group <- ifelse(CoefficientsEN$`Change in Log Odds per Unit Increase` < 0,
levels(input_to_reg$Group)[1],
levels(input_to_reg$Group)[2])
#Plot coefficients in waterfall plot
logoddsvalue = CoefficientsEN$`Change in Log Odds per Unit Increase`
features = rownames(CoefficientsEN)
#Extract log odds coefficients
bestEN <- ElasticNet$finalModel
CoefficientsEN = as.matrix(coef(bestEN, s = ElasticNet$bestTune$lambda))
CoefficientsEN = as.data.frame(CoefficientsEN)
rownames(CoefficientsEN) = stringr::str_replace_all(rownames(CoefficientsEN),
"[`]", "")
colnames(CoefficientsEN)[1] = "Change in Log Odds per Unit Increase"
#Set up Coefficients waterfall plot data
CoefficientsEN = subset(CoefficientsEN, CoefficientsEN$`Change in Log Odds per Unit Increase`!=0)
CoefficientsEN = CoefficientsEN[2:nrow(CoefficientsEN),,drop = FALSE]
CoefficientsEN = CoefficientsEN[order(-CoefficientsEN$`Change in Log Odds per Unit Increase`),
, drop = FALSE]
CoefficientsEN$`Group` <- rownames(CoefficientsEN)  # create new column for car names
CoefficientsEN$Group <- ifelse(CoefficientsEN$`Change in Log Odds per Unit Increase` < 0,
levels(input$Group)[1],
levels(input$Group)[2])
#Plot coefficients in waterfall plot
logoddsvalue = CoefficientsEN$`Change in Log Odds per Unit Increase`
features = rownames(CoefficientsEN)
features = factor(features, levels = features[order(logoddsvalue)])
axval = (max(abs(logoddsvalue)) + 0.03)
plot_coef = ggplot(CoefficientsEN, aes(x=features, y=logoddsvalue)) +
geom_bar(stat='identity', aes(fill=Group), width=.6)  +
scale_fill_manual(name="Group",
labels = c(levels(input$Group)[1],levels(input$Group)[2]),
values = plot_colors
) +
labs(subtitle="", title= "") +
theme(text = element_text(size=0.5),
axis.text.x = element_text(face="bold", color="black", size=2.5, angle=0),
axis.text.y = element_text(face="bold", color="black", size=2.5, angle=0),
panel.background = element_blank(),
axis.line = element_line(colour = "black", size = 0.15),
panel.grid = element_line(colour = "grey", size = 0.1),
plot.margin = unit(c(2,2,2,2), "mm"),
axis.title.y = element_text(angle = 90, vjust = 1, hjust = 0.5, size = 4),
axis.title.x = element_text(angle = 0, vjust = -0.3, hjust = 0.5, size = 4),
plot.title = element_text(vjust=3, hjust = 0),
plot.subtitle = element_text(vjust = 3),
legend.title = element_text(size=2),
legend.text = element_text(size=2),
legend.key.size = unit(0.3,"line"),
legend.margin = ggplot2::margin(t=-0.5, unit = "mm")) +
labs(x = "Cell Type", y = expression(paste(Delta, "Log Odds/","Unit Increase"))) +
scale_y_continuous(limits = c(-axval, axval)) +
coord_flip()
plot_coef = ggplot(CoefficientsEN, aes(x=features, y=logoddsvalue)) +
geom_bar(stat='identity', aes(fill=Group), width=.6)  +
scale_fill_manual(name="Group",
labels = c(levels(input$Group)[1],levels(input$Group)[2]),
values = c("Black","Grey")
) +
labs(subtitle="", title= "") +
theme(text = element_text(size=0.5),
axis.text.x = element_text(face="bold", color="black", size=2.5, angle=0),
axis.text.y = element_text(face="bold", color="black", size=2.5, angle=0),
panel.background = element_blank(),
axis.line = element_line(colour = "black", size = 0.15),
panel.grid = element_line(colour = "grey", size = 0.1),
plot.margin = unit(c(2,2,2,2), "mm"),
axis.title.y = element_text(angle = 90, vjust = 1, hjust = 0.5, size = 4),
axis.title.x = element_text(angle = 0, vjust = -0.3, hjust = 0.5, size = 4),
plot.title = element_text(vjust=3, hjust = 0),
plot.subtitle = element_text(vjust = 3),
legend.title = element_text(size=2),
legend.text = element_text(size=2),
legend.key.size = unit(0.3,"line"),
legend.margin = ggplot2::margin(t=-0.5, unit = "mm")) +
labs(x = "Cell Type", y = expression(paste(Delta, "Log Odds/","Unit Increase"))) +
scale_y_continuous(limits = c(-axval, axval)) +
coord_flip()
ggsave(paste(levels(input$Group)[1],
levels(input$Group)[2],
"coeff_plot.jpeg",sep="_"),plot = plot_coef, units = "mm", width = 50, height = 50)
View(bestEN)
#Export cross validation summary
if (export_cv){
cvSummary = as.data.frame(ElasticNet$results)
write.xlsx(cvSummary, paste(levels(input$Group)[1],
levels(input$Group)[2],
"Cross_valid_summary.xlsx",sep = "_"))
}
setwd("/Volumes/viclab$/Reeves Team/Josh Hess/gists/Linear-Discriminant-Analysis")
#Import modules (Do not change)
source("MasterLDA.R")
#Enter the name of your data file (If multiple files, use: c("File1name.xlsx","File2name.xlsx"))
filename = "For Correlation Analysis 10302019.xlsx"
#Enter the name of the sheet of the data sheet you are using for calculations (If multiple sheets, use: c("Sheet1name.xlsx","Sheet2name.xlsx"))
sheetname = "Sheet1"
#Scale your data? (z-score)
scale_clusters = TRUE
#Do you want to add a prefix to cluster names? If not, leave as NULL (If multiple sheets, use: c("B","I"))
cluster_prefix = NULL
#Which columns are you using as cells for calculation? (Variables in your excel sheet)
cell_cols = 20:31
#Which columns are you using as clinical measures? If none, use NULL and calculation will only be run for cells. (Variables in your excel sheet)
not_cell_cols = 2:5
#Which column indicates the groups you are using? (Variables in your excel sheet)
group_col = 3
#Which groups are you wanting to use? (Ex. groups = c(1,2,3) if numbered Ex. groups = c("Vaccinated","Naive","Vax Sick") if strings)
groups = c(1,2)
#Which type of cross-validation (Options are "repeated" or "bootstrap")
cv_type = "repeated"
#Export an excile file containing performance metrics per cluster in iterative LDA?
export_results_iterative = TRUE
#Keep this many clusters (based on top classification accuracy) after single cluster LDAs
top_n = 3
#Export an image containing performance metrics for combinations of clusters?
export_results_permutative = TRUE
#Maxmimum number of clusters per combination to test?
max_size = 2
#What are the new group assignments for LDA predictions and projections (include those you uused in "groups" argument plus any more for projection of continuous change)
new_groups = c(1,2,3)
#How many cores to use for the calculations? (Ex: 10)
num_cores = 8
#Run the LDA pipeline
results = MasterLDA(filename,sheetname,group_col,groups,cell_cols,not_cell_cols,scale_clusters=TRUE,cluster_prefix=NULL,
cv_type,export_results_iterative,num_cores,
top_n,export_results_permutative,
max_size,
new_groups = NULL)
#Import modules (Do not change)
source("MasterLDA.R")
#Enter the name of your data file (If multiple files, use: c("File1name.xlsx","File2name.xlsx"))
filename = "For Correlation Analysis 10302019.xlsx"
#Enter the name of the sheet of the data sheet you are using for calculations (If multiple sheets, use: c("Sheet1name.xlsx","Sheet2name.xlsx"))
sheetname = "Sheet1"
#Scale your data? (z-score)
scale_clusters = TRUE
#Do you want to add a prefix to cluster names? If not, leave as NULL (If multiple sheets, use: c("B","I"))
cluster_prefix = NULL
#Which columns are you using as cells for calculation? (Variables in your excel sheet)
cell_cols = 20:31
#Which columns are you using as clinical measures? If none, use NULL and calculation will only be run for cells. (Variables in your excel sheet)
not_cell_cols = 2:5
#Which column indicates the groups you are using? (Variables in your excel sheet)
group_col = 3
#Which groups are you wanting to use? (Ex. groups = c(1,2,3) if numbered Ex. groups = c("Vaccinated","Naive","Vax Sick") if strings)
groups = c(1,2)
#Which type of cross-validation (Options are "repeated" or "bootstrap")
cv_type = "repeated"
#Export an excile file containing performance metrics per cluster in iterative LDA?
export_results_iterative = TRUE
#Keep this many clusters (based on top classification accuracy) after single cluster LDAs
top_n = 3
#Export an image containing performance metrics for combinations of clusters?
export_results_permutative = TRUE
#Maxmimum number of clusters per combination to test?
max_size = 2
#What are the new group assignments for LDA predictions and projections (include those you uused in "groups" argument plus any more for projection of continuous change)
new_groups = c(1,2,3)
#How many cores to use for the calculations? (Ex: 10)
num_cores = 8
#Run the LDA pipeline
results = MasterLDA(filename,sheetname,group_col,groups,cell_cols,not_cell_cols,scale_clusters=TRUE,cluster_prefix=NULL,
cv_type,export_results_iterative,num_cores,
top_n,export_results_permutative,
max_size,
new_groups = NULL)
#Import modules (Do not change)
source("MasterLDA.R")
#Enter the name of your data file (If multiple files, use: c("File1name.xlsx","File2name.xlsx"))
filename = "For Correlation Analysis 10302019.xlsx"
#Enter the name of the sheet of the data sheet you are using for calculations (If multiple sheets, use: c("Sheet1name.xlsx","Sheet2name.xlsx"))
sheetname = "Sheet1"
#Scale your data? (z-score)
scale_clusters = TRUE
#Do you want to add a prefix to cluster names? If not, leave as NULL (If multiple sheets, use: c("B","I"))
cluster_prefix = NULL
#Which columns are you using as cells for calculation? (Variables in your excel sheet)
cell_cols = 20:31
#Which columns are you using as clinical measures? If none, use NULL and calculation will only be run for cells. (Variables in your excel sheet)
not_cell_cols = 2:5
#Which column indicates the groups you are using? (Variables in your excel sheet)
group_col = 3
#Which groups are you wanting to use? (Ex. groups = c(1,2,3) if numbered Ex. groups = c("Vaccinated","Naive","Vax Sick") if strings)
groups = c(1,2)
#Which type of cross-validation (Options are "repeated" or "bootstrap")
cv_type = "repeated"
#Export an excile file containing performance metrics per cluster in iterative LDA?
export_results_iterative = TRUE
#Keep this many clusters (based on top classification accuracy) after single cluster LDAs
top_n = 3
#Export an image containing performance metrics for combinations of clusters?
export_results_permutative = TRUE
#Maxmimum number of clusters per combination to test?
max_size = 2
#What are the new group assignments for LDA predictions and projections (include those you uused in "groups" argument plus any more for projection of continuous change)
new_groups = c(1,2,3)
#How many cores to use for the calculations? (Ex: 10)
num_cores = 8
#Run the LDA pipeline
results = MasterLDA(filename,sheetname,group_col,groups,cell_cols,not_cell_cols,scale_clusters=TRUE,cluster_prefix=NULL,
cv_type,export_results_iterative,num_cores,
top_n,export_results_permutative,
max_size,new_groups)
